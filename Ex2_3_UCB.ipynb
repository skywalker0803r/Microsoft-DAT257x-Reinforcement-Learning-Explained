{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Ex2.3 UCB.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywalker0803r/Microsoft-DAT257x-Reinforcement-Learning-Explained/blob/master/Ex2_3_UCB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ups5hbdT0u6B",
        "colab_type": "text"
      },
      "source": [
        "# DAT257x: Reinforcement Learning Explained\n",
        "\n",
        "## Lab 2: Bandits\n",
        "\n",
        "### Exercise 2.3: UCB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X53hKzxM2vCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "### Interface\n",
        "class Environment(object):\n",
        "\n",
        "    def reset(self):\n",
        "        raise NotImplementedError('Inheriting classes must override reset.')\n",
        "\n",
        "    def actions(self):\n",
        "        raise NotImplementedError('Inheriting classes must override actions.')\n",
        "\n",
        "    def step(self):\n",
        "        raise NotImplementedError('Inheriting classes must override step')\n",
        "\n",
        "class ActionSpace(object):\n",
        "    \n",
        "    def __init__(self, actions):\n",
        "        self.actions = actions\n",
        "        self.n = len(actions)\n",
        "        \n",
        "### BanditEnv Environment\n",
        "        \n",
        "class BanditEnv(Environment):\n",
        "    def __init__(self, num_actions = 10, distribution = \"bernoulli\", evaluation_seed=\"387\"):\n",
        "        super(BanditEnv, self).__init__()\n",
        "        \n",
        "        self.action_space = ActionSpace(range(num_actions))\n",
        "        self.distribution = distribution\n",
        "        \n",
        "        np.random.seed(evaluation_seed)\n",
        "        \n",
        "        self.reward_parameters = None\n",
        "        if distribution == \"bernoulli\":\n",
        "            self.reward_parameters = np.random.rand(num_actions)\n",
        "        elif distribution == \"normal\":\n",
        "            self.reward_parameters = (np.random.randn(num_actions), np.random.rand(num_actions))\n",
        "        elif distribution == \"heavy-tail\":\n",
        "            self.reward_parameters = np.random.rand(num_actions)\n",
        "        else:\n",
        "            print(\"Please use a supported reward distribution\", flush = True)\n",
        "            sys.exit(0)\n",
        "        \n",
        "        if distribution != \"normal\":\n",
        "            self.optimal_arm = np.argmax(self.reward_parameters)\n",
        "        else:\n",
        "            self.optimal_arm = np.argmax(self.reward_parameters[0])\n",
        "    \n",
        "    def reset(self):\n",
        "        self.is_reset = True\n",
        "        return None\n",
        "    \n",
        "    def compute_gap(self, action):\n",
        "        if self.distribution != \"normal\":\n",
        "            gap = np.absolute(self.reward_parameters[self.optimal_arm] - self.reward_parameters[action])\n",
        "        else:\n",
        "            gap = np.absolute(self.reward_parameters[0][self.optimal_arm] - self.reward_parameters[0][action])\n",
        "        return gap\n",
        "    \n",
        "    def step(self, action):\n",
        "        self.is_reset = False\n",
        "        valid_action = True\n",
        "        if (action is None or action < 0 or action >= self.action_space.n):\n",
        "            print(\"Algorithm chose an invalid action; reset reward to -inf\", flush = True)\n",
        "            reward = float(\"-inf\")\n",
        "            gap = float(\"inf\")\n",
        "            valid_action = False\n",
        "        \n",
        "        if self.distribution == \"bernoulli\":\n",
        "            if valid_action:\n",
        "                reward = np.random.binomial(1, self.reward_parameters[action])\n",
        "                gap = self.reward_parameters[self.optimal_arm] - self.reward_parameters[action]\n",
        "        elif self.distribution == \"normal\":\n",
        "            if valid_action:\n",
        "                reward = self.reward_parameters[0][action] + self.reward_parameters[1][action] * np.random.randn()\n",
        "                gap = self.reward_parameters[0][self.optimal_arm] - self.reward_parameters[0][action]\n",
        "        elif self.distribution == \"heavy-tail\":\n",
        "            if valid_action:\n",
        "                reward = self.reward_parameters[action] + np.random.standard_cauchy()\n",
        "                gap = self.reward_parameters[self.optimal_arm] - self.reward_parameters[action]        #HACK to compute expected gap\n",
        "        else:\n",
        "            print(\"Please use a supported reward distribution\", flush = True)\n",
        "            sys.exit(0)\n",
        "            \n",
        "        return(None, reward, self.is_reset, '')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import namedtuple\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "EpisodeStats = namedtuple(\"Stats\",[\"episode_lengths\", \"episode_rewards\", \"episode_running_variance\"])\n",
        "TimestepStats = namedtuple(\"Stats\",[\"cumulative_rewards\", \"regrets\"])\n",
        "\n",
        "def plot_episode_stats(stats, smoothing_window=10, hideplot=False):\n",
        "    # Plot the episode length over time\n",
        "    fig1 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(stats.episode_lengths)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Episode Length\")\n",
        "    plt.title(\"Episode Length over Time\")\n",
        "    if hideplot:\n",
        "        plt.close(fig1)\n",
        "    else:\n",
        "        plt.show(fig1)\n",
        "\n",
        "    # Plot the episode reward over time\n",
        "    fig2 = plt.figure(figsize=(10,5))\n",
        "    rewards_smoothed = pd.Series(stats.episode_rewards).rolling(smoothing_window, min_periods=smoothing_window).mean()\n",
        "    plt.plot(rewards_smoothed)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Episode Reward (Smoothed)\")\n",
        "    plt.title(\"Episode Reward over Time (Smoothed over window size {})\".format(smoothing_window))\n",
        "    if hideplot:\n",
        "        plt.close(fig2)\n",
        "    else:\n",
        "        plt.show(fig2)\n",
        "\n",
        "    return fig1, fig2\n",
        "\n",
        "def plot_pgresults(stats, smoothing_window=20, hideplot=False):\n",
        "    # Plot the episode length over time\n",
        "    fig1 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(stats.episode_lengths)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Episode Length\")\n",
        "    plt.title(\"Episode Length over Time\")\n",
        "    if hideplot:\n",
        "        plt.close(fig1)\n",
        "    else:\n",
        "        plt.show(fig1)\n",
        "\n",
        "    # Plot the episode reward over time\n",
        "    fig2 = plt.figure(figsize=(10,5))\n",
        "    rewards_smoothed = pd.Series(stats.episode_rewards).rolling(smoothing_window, min_periods=smoothing_window).mean()\n",
        "    plt.plot(rewards_smoothed)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Episode Reward (Smoothed)\")\n",
        "    plt.title(\"Episode Reward over Time (Smoothed over window size {})\".format(smoothing_window))\n",
        "    if hideplot:\n",
        "        plt.close(fig2)\n",
        "    else:\n",
        "        plt.show(fig2)\n",
        "       \n",
        "    # Plot time steps and episode number\n",
        "    fig3 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(stats.episode_running_variance)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Running Variance\")\n",
        "    plt.title(\"Running Variance over Time\")\n",
        "    if hideplot:\n",
        "        plt.close(fig3)\n",
        "    else:\n",
        "        plt.show(fig3)\n",
        "        \n",
        "    # Plot time steps and episode number\n",
        "    fig4 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(np.arange(len(stats.episode_lengths)), np.cumsum(stats.episode_lengths))\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Cumulative Episode Length\")\n",
        "    plt.title(\"Cumulative Episode Length over Time\")\n",
        "    if hideplot:\n",
        "        plt.close(fig4)\n",
        "    else:\n",
        "        plt.show(fig4)\n",
        "\n",
        "    return fig1, fig2, fig3, fig4\n",
        "\n",
        "def plot_dqnresults(stats, smoothing_window=20, hideplot=False):\n",
        "    # Plot the episode length over time\n",
        "    fig1 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(stats.episode_lengths)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Episode Length\")\n",
        "    plt.title(\"Episode Length over Time\")\n",
        "    if hideplot:\n",
        "        plt.close(fig1)\n",
        "    else:\n",
        "        plt.show(fig1)\n",
        "\n",
        "    # Plot the episode reward over time\n",
        "    fig2 = plt.figure(figsize=(10,5))\n",
        "    rewards_smoothed = pd.Series(stats.episode_rewards).rolling(smoothing_window, min_periods=smoothing_window).mean()\n",
        "    plt.plot(rewards_smoothed)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Episode Reward (Smoothed)\")\n",
        "    plt.title(\"Episode Reward over Time (Smoothed over window size {})\".format(smoothing_window))\n",
        "    if hideplot:\n",
        "        plt.close(fig2)\n",
        "    else:\n",
        "        plt.show(fig2)\n",
        "              \n",
        "    # Plot time steps and episode number\n",
        "    fig4 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(np.arange(len(stats.episode_lengths)), np.cumsum(stats.episode_lengths))\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Cumulative Episode Length\")\n",
        "    plt.title(\"Cumulative Episode Length over Time\")\n",
        "    if hideplot:\n",
        "        plt.close(fig4)\n",
        "    else:\n",
        "        plt.show(fig4)\n",
        "\n",
        "    return fig1, fig2, fig3, fig4\n",
        "\n",
        "def plot_reward_regret(stats, smoothing_window=1, hideplot=False):\n",
        "    # Plot the cumulative reward over time\n",
        "    fig1 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(stats.cumulative_rewards)\n",
        "    plt.xlabel(\"Timestep\")\n",
        "    plt.ylabel(\"Cumulative Reward\")\n",
        "    plt.title(\"Cumulative Reward over Timestep\")\n",
        "    if hideplot:\n",
        "        plt.close(fig1)\n",
        "    else:\n",
        "        plt.show(fig1)\n",
        "\n",
        "    # Plot the regret over time\n",
        "    fig2 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(stats.regrets)\n",
        "    plt.xlabel(\"Timestep\")\n",
        "    plt.ylabel(\"Regret\")\n",
        "    plt.title(\"Regret over Timestep\")\n",
        "    if hideplot:\n",
        "        plt.close(fig2)\n",
        "    else:\n",
        "        plt.show(fig2)\n",
        "             \n",
        "    return fig1, fig2   \n",
        "\n",
        "def plot_arm_rewards(y, hideplot=False):\n",
        "    \n",
        "    N = len(y)\n",
        "    x = range(N)\n",
        "    width = 1/1.5\n",
        "    \n",
        "    fig1 = plt.figure(figsize=(10,5))\n",
        "    plt.bar(x, y, width)\n",
        "    \n",
        "    plt.xlabel(\"Arm\")\n",
        "    plt.ylabel(\"Probability\")\n",
        "    plt.title(\"Arm's Reward Distribution\")\n",
        "    \n",
        "    if hideplot:\n",
        "        plt.close(fig1)\n",
        "    else:\n",
        "        plt.show(fig1)\n",
        "             \n",
        "    return fig1\n",
        "import numpy as np\n",
        "import sys\n",
        "#import lib.plotting as plotting\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import pylab\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "class Experiment(object):\n",
        "    def __init__(self, env, agent):\n",
        "        \n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        \n",
        "        self.episode_length = np.array([0])\n",
        "        self.episode_reward = np.array([0])\n",
        "        \n",
        "        self.fig = pylab.figure(figsize=(10, 5))\n",
        "        gs = gridspec.GridSpec(2, 2)\n",
        "        self.ax = pylab.subplot(gs[:, 0])\n",
        "        self.ax.xaxis.set_visible(False)\n",
        "        self.ax.yaxis.set_visible(False)\n",
        "        \n",
        "        if hasattr(self.env, '_cliff'): # Hardcode to nicely display grid for cliffwalkingenv\n",
        "            self.ax.xaxis.set_visible(True)\n",
        "            self.ax.yaxis.set_visible(True)\n",
        "            self.ax.set_xticks(np.arange(-.5, 12, 1), minor=True);\n",
        "            self.ax.set_yticks(np.arange(-.5, 4, 1), minor=True);\n",
        "            self.ax.grid(which='minor', color='w', linestyle='-', linewidth=1)\n",
        "            \n",
        "        if hasattr(self.env, 'winds'): # Hardcode to nicely display grid for windygridworldenv\n",
        "            self.ax.xaxis.set_visible(True)\n",
        "            self.ax.yaxis.set_visible(True)\n",
        "            self.ax.set_xticks(np.arange(-.5, 10, 1), minor=True);\n",
        "            self.ax.set_yticks(np.arange(-.5, 7, 1), minor=True);\n",
        "            self.ax.grid(which='minor', color='w', linestyle='-', linewidth=1)\n",
        "        \n",
        "        self.ax1 = pylab.subplot(gs[0, 1])\n",
        "        self.ax1.yaxis.set_label_position(\"right\")\n",
        "        self.ax1.set_ylabel('Length')\n",
        "        \n",
        "        self.ax1.set_xlim(0, max(10, len(self.episode_length)+1))\n",
        "        self.ax1.set_ylim(0, 51)\n",
        "        \n",
        "        self.ax2 = pylab.subplot(gs[1, 1])\n",
        "        self.ax2.set_xlabel('Episode')\n",
        "        self.ax2.yaxis.set_label_position(\"right\")\n",
        "        self.ax2.set_ylabel('Reward')\n",
        "        self.ax2.set_xlim(0, max(10, len(self.episode_reward)+1))\n",
        "        self.ax2.set_ylim(0, 2)\n",
        "        \n",
        "        self.line, = self.ax1.plot(range(len(self.episode_length)),self.episode_length)\n",
        "        self.line2, = self.ax2.plot(range(len(self.episode_reward)),self.episode_reward)\n",
        "        \n",
        "    def update_display_step(self):\n",
        "        if not hasattr(self, 'imgplot'):\n",
        "            self.imgplot = self.ax.imshow(self.env.render(mode='rgb_array'), interpolation='none', cmap='viridis')\n",
        "        else:\n",
        "            self.imgplot.set_data(self.env.render(mode='rgb_array'))\n",
        "    \n",
        "        self.fig.canvas.draw()\n",
        "        \n",
        "    def update_display_episode(self):  \n",
        "        self.line.set_data(range(len(self.episode_length)),self.episode_length)\n",
        "        self.ax1.set_xlim(0, max(10, len(self.episode_length)+1))\n",
        "        self.ax1.set_ylim(0, max(self.episode_length)+1)\n",
        "        \n",
        "        self.line2.set_data(range(len(self.episode_reward)),self.episode_reward)\n",
        "        self.ax2.set_xlim(0, max(10, len(self.episode_reward)+1))\n",
        "        self.ax2.set_ylim(min(self.episode_reward)-1, max(self.episode_reward)+1)\n",
        "        \n",
        "        self.fig.canvas.draw()     \n",
        "        \n",
        "    def run_bandit(self, max_number_of_trials=1000, display_frequency=1):\n",
        "        self.fig.clf()\n",
        "        \n",
        "        print(\"Distribution:\", self.env.distribution, self.env.reward_parameters, flush = True)\n",
        "        print(\"Optimal arm:\", self.env.optimal_arm, flush = True)\n",
        "        \n",
        "        if self.env.distribution != \"normal\":\n",
        "            plot_arm_rewards(self.env.reward_parameters)\n",
        "        #else:\n",
        "            #plotting.plot_arm_rewards(self.env.reward_parameters[0])\n",
        "        \n",
        "        stats = TimestepStats(\n",
        "            cumulative_rewards=np.zeros(max_number_of_trials),\n",
        "            regrets=np.zeros(max_number_of_trials))   \n",
        "            \n",
        "        cumulative_reward = 0.0\n",
        "        cumulative_regret = 0.0\n",
        "        \n",
        "        for trial in range(max_number_of_trials):\n",
        "            action = self.agent.act()\n",
        "            \n",
        "            _ , reward, done, _ = self.env.step(action)       \n",
        "            self.agent.feedback(action, reward)\n",
        "            cumulative_reward += reward\n",
        "\n",
        "            gap = self.env.compute_gap(action)\n",
        "            if action != self.env.optimal_arm:\n",
        "                cumulative_regret += gap\n",
        "\n",
        "            stats.cumulative_rewards[trial] = cumulative_reward\n",
        "            stats.regrets[trial] = cumulative_regret\n",
        "            \n",
        "\n",
        "        print(\"--------------------------------------------------\", flush = True)\n",
        "        print(\"Policy:\", self.agent.name, \"\\nAverage Reward:\", cumulative_reward / max_number_of_trials, \\\n",
        "                \"\\nAverage Regret:\", cumulative_regret / max_number_of_trials, flush = True)\n",
        "        print(\"Arm pulls:\", self.agent.total_counts, flush = True)\n",
        "         \n",
        "        plot_reward_regret(stats)\n",
        "        \n",
        "    def run_agent(self, max_number_of_episodes=100, interactive = False, display_frequency=1):\n",
        "\n",
        "        # repeat for each episode\n",
        "        for episode_number in range(max_number_of_episodes):\n",
        "            \n",
        "            # initialize state\n",
        "            state = self.env.reset()\n",
        "            \n",
        "            done = False # used to indicate terminal state\n",
        "            R = 0 # used to display accumulated rewards for an episode\n",
        "            t = 0 # used to display accumulated steps for an episode i.e episode length\n",
        "            \n",
        "            # repeat for each step of episode, until state is terminal\n",
        "            while not done:\n",
        "                \n",
        "                # increase step counter - for display\n",
        "                t += 1\n",
        "                \n",
        "                # choose action from state \n",
        "                action = self.agent.act(state)\n",
        "                \n",
        "                # take action, observe reward and next state\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "                \n",
        "                # state <- next state\n",
        "                state = next_state\n",
        "                \n",
        "                R += reward # accumulate reward - for display\n",
        "                \n",
        "                # if interactive display, show update for each step\n",
        "                if interactive:\n",
        "                    self.update_display_step()\n",
        "            \n",
        "            self.episode_length = np.append(self.episode_length,t) # keep episode length - for display\n",
        "            self.episode_reward = np.append(self.episode_reward,R) # keep episode reward - for display \n",
        "            \n",
        "            # if interactive display, show update for the episode\n",
        "            if interactive:\n",
        "                self.update_display_episode()\n",
        "        \n",
        "        # if not interactive display, show graph at the end\n",
        "        if not interactive:\n",
        "            self.fig.clf()\n",
        "            stats = EpisodeStats(\n",
        "                episode_lengths=self.episode_length,\n",
        "                episode_rewards=self.episode_reward,\n",
        "                episode_running_variance=np.zeros(max_number_of_episodes))\n",
        "            plot_episode_stats(stats, display_frequency)\n",
        "        \n",
        "  \n",
        "    def run_qlearning(self, max_number_of_episodes=100, interactive = False, display_frequency=1):\n",
        "\n",
        "        # repeat for each episode\n",
        "        for episode_number in range(max_number_of_episodes):\n",
        "            \n",
        "            # initialize state\n",
        "            state = self.env.reset()\n",
        "            \n",
        "            done = False # used to indicate terminal state\n",
        "            R = 0 # used to display accumulated rewards for an episode\n",
        "            t = 0 # used to display accumulated steps for an episode i.e episode length\n",
        "            \n",
        "            # repeat for each step of episode, until state is terminal\n",
        "            while not done:\n",
        "                \n",
        "                t += 1 # increase step counter - for display\n",
        "                \n",
        "                # choose action from state using policy derived from Q\n",
        "                action = self.agent.act(state)\n",
        "                \n",
        "                # take action, observe reward and next state\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "                \n",
        "                # agent learn (Q-Learning update)\n",
        "                self.agent.learn(state, action, reward, next_state, done)\n",
        "                \n",
        "                # state <- next state\n",
        "                state = next_state\n",
        "                \n",
        "                R += reward # accumulate reward - for display\n",
        "                \n",
        "                # if interactive display, show update for each step\n",
        "                if interactive:\n",
        "                    self.update_display_step()\n",
        "            \n",
        "            self.episode_length = np.append(self.episode_length,t) # keep episode length - for display\n",
        "            self.episode_reward = np.append(self.episode_reward,R) # keep episode reward - for display \n",
        "            \n",
        "            # if interactive display, show update for the episode\n",
        "            if interactive:\n",
        "                self.update_display_episode()\n",
        "        \n",
        "        # if not interactive display, show graph at the end\n",
        "        if not interactive:\n",
        "            self.fig.clf()\n",
        "            stats = EpisodeStats(\n",
        "                episode_lengths=self.episode_length,\n",
        "                episode_rewards=self.episode_reward,\n",
        "                episode_running_variance=np.zeros(max_number_of_episodes))\n",
        "            plot_episode_stats(stats, display_frequency)\n",
        "            \n",
        "    def run_sarsa(self, max_number_of_episodes=100, interactive = False, display_frequency=1):\n",
        "\n",
        "        # repeat for each episode\n",
        "        for episode_number in range(max_number_of_episodes):\n",
        "            \n",
        "            # initialize state\n",
        "            state = self.env.reset()\n",
        "\n",
        "            done = False # used to indicate terminal state\n",
        "            R = 0 # used to display accumulated rewards for an episode\n",
        "            t = 0 # used to display accumulated steps for an episode i.e episode length\n",
        "            \n",
        "            # choose action from state using policy derived from Q\n",
        "            action = self.agent.act(state)\n",
        "            \n",
        "            # repeat for each step of episode, until state is terminal\n",
        "            while not done:\n",
        "                \n",
        "                t += 1 # increase step counter - for display\n",
        "                \n",
        "                # take action, observe reward and next state\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "                \n",
        "                # choose next action from next state using policy derived from Q\n",
        "                next_action = self.agent.act(next_state)\n",
        "                \n",
        "                # agent learn (SARSA update)\n",
        "                self.agent.learn(state, action, reward, next_state, next_action)\n",
        "                \n",
        "                # state <- next state, action <- next_action\n",
        "                state = next_state\n",
        "                action = next_action\n",
        "\n",
        "                R += reward # accumulate reward - for display\n",
        "                \n",
        "                # if interactive display, show update for each step\n",
        "                if interactive:\n",
        "                    self.update_display_step()\n",
        "            \n",
        "            self.episode_length = np.append(self.episode_length,t) # keep episode length - for display\n",
        "            self.episode_reward = np.append(self.episode_reward,R) # keep episode reward - for display \n",
        "            \n",
        "            # if interactive display, show update for the episode\n",
        "            if interactive:\n",
        "                self.update_display_episode()\n",
        "        \n",
        "        # if not interactive display, show graph at the end\n",
        "        if not interactive:\n",
        "            self.fig.clf()\n",
        "            stats = EpisodeStats(\n",
        "                episode_lengths=self.episode_length,\n",
        "                episode_rewards=self.episode_reward,\n",
        "                episode_running_variance=np.zeros(max_number_of_episodes))\n",
        "            plot_episode_stats(stats, display_frequency)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlGVGJIj0u6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "if \"../\" not in sys.path:\n",
        "    sys.path.append(\"../\") \n",
        "\n",
        "#from lib.envs.bandit import BanditEnv\n",
        "#from lib.simulation import Experiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4If01IDs0u6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Policy interface\n",
        "class Policy:\n",
        "    #num_actions: (int) Number of arms [indexed by 0 ... num_actions-1]\n",
        "    def __init__(self, num_actions):\n",
        "        self.num_actions = num_actions\n",
        "    \n",
        "    def act(self):\n",
        "        pass\n",
        "        \n",
        "    def feedback(self, action, reward):\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqUFN7r10u6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Greedy policy\n",
        "class Greedy(Policy):\n",
        "    def __init__(self, num_actions):\n",
        "        Policy.__init__(self, num_actions)\n",
        "        self.name = \"Greedy\"\n",
        "        self.total_rewards = np.zeros(num_actions, dtype = np.longdouble)\n",
        "        self.total_counts = np.zeros(num_actions, dtype = np.longdouble)\n",
        "    \n",
        "    def act(self):\n",
        "        current_averages = np.divide(self.total_rewards, self.total_counts, where = self.total_counts > 0)\n",
        "        current_averages[self.total_counts <= 0] = 0.5      #Correctly handles Bernoulli rewards; over-estimates otherwise\n",
        "        current_action = np.argmax(current_averages)\n",
        "        return current_action\n",
        "        \n",
        "    def feedback(self, action, reward):\n",
        "        self.total_rewards[action] += reward\n",
        "        self.total_counts[action] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB-H6bXY0u7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Epsilon Greedy policy\n",
        "class EpsilonGreedy(Greedy):\n",
        "    def __init__(self, num_actions, epsilon):\n",
        "        Greedy.__init__(self, num_actions)\n",
        "        if (epsilon is None or epsilon < 0 or epsilon > 1):\n",
        "            print(\"EpsilonGreedy: Invalid value of epsilon\", flush = True)\n",
        "            sys.exit(0)\n",
        "            \n",
        "        self.epsilon = epsilon\n",
        "        self.name = \"Epsilon Greedy\"\n",
        "    \n",
        "    def act(self):\n",
        "        choice = None\n",
        "        if self.epsilon == 0:\n",
        "            choice = 0\n",
        "        elif self.epsilon == 1:\n",
        "            choice = 1\n",
        "        else:\n",
        "            choice = np.random.binomial(1, self.epsilon)\n",
        "            \n",
        "        if choice == 1:\n",
        "            return np.random.choice(self.num_actions)\n",
        "        else:\n",
        "            current_averages = np.divide(self.total_rewards, self.total_counts, where = self.total_counts > 0)\n",
        "            current_averages[self.total_counts <= 0] = 0.5  #Correctly handles Bernoulli rewards; over-estimates otherwise\n",
        "            current_action = np.argmax(current_averages)\n",
        "            return current_action\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOkRjVaO0u7N",
        "colab_type": "text"
      },
      "source": [
        "Now let's implement a UCB algorithm. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92yoRjz_2F3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#UCB policy\n",
        "class UCB(Greedy):\n",
        "    def __init__(self, num_actions):\n",
        "        Greedy.__init__(self, num_actions)\n",
        "        self.name = \"UCB\"\n",
        "        self.round = 0\n",
        "        self.total_rewards = np.zeros(num_actions, dtype = np.longdouble)\n",
        "        self.total_counts = np.zeros(num_actions, dtype = np.longdouble)        \n",
        "        \n",
        "    def act(self):\n",
        "        current_action = None\n",
        "        self.round += 1\n",
        "        if self.round <= self.num_actions:\n",
        "            \"\"\"The first k rounds, where k is the number of arms/actions, play each arm/action once\"\"\"\n",
        "            current_action = self.round - 1\n",
        "#             current_action = 0\n",
        "        else:\n",
        "            \"\"\"At round t, play the arms with maximum average and exploration bonus\"\"\"\n",
        "            assert np.min(self.total_counts) > 0, \"np.min(self.total_counts) <= 0\"\n",
        "            current_averages = np.divide(self.total_rewards, self.total_counts, where = self.total_counts > 0)\n",
        "#             current_averages[self.total_counts <= 0] = 0.5  #Correctly handles Bernoulli rewards; over-estimates otherwise\n",
        "            current_exploration_bonus = np.sqrt(2.0 * np.log(self.round) / self.total_counts)\n",
        "            current_action = np.argmax(current_averages + current_exploration_bonus)            \n",
        "#             current_action = 0\n",
        "        return current_action\n",
        "    \n",
        "    def feedback(self, action, reward):\n",
        "        self.total_rewards[action] += reward\n",
        "        self.total_counts[action] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXFjYTIN0u7b",
        "colab_type": "text"
      },
      "source": [
        "Now let's prepare the simulation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COvlVuuq0u7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluation_seed = 1239\n",
        "#num_actions = 10\n",
        "#trials = 10000\n",
        "#distribution = \"bernoulli\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Njmw-dJ3l_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_seed = 1239\n",
        "num_actions = 10\n",
        "trials = 10000\n",
        "distribution = \"normal\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-fgEbBC0u7p",
        "colab_type": "text"
      },
      "source": [
        "What do you think the regret graph would look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A3Yxdf40u7t",
        "colab_type": "code",
        "outputId": "e4fa9270-80b2-4cbb-d9f9-630a85319689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        }
      },
      "source": [
        "env = BanditEnv(num_actions, distribution, evaluation_seed)\n",
        "agent = UCB(num_actions)\n",
        "experiment = Experiment(env, agent)\n",
        "experiment.run_bandit(trials)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution: normal (array([ 1.67210906,  0.04144904, -2.26004314,  0.55185287, -0.99557374,\n",
            "       -0.2838564 , -0.50553487, -0.05963477, -0.54748047,  0.61487342]), array([0.16003572, 0.39623439, 0.70679209, 0.13345484, 0.97314585,\n",
            "       0.28711056, 0.11221114, 0.52693607, 0.53345874, 0.62434873]))\n",
            "Optimal arm: 0\n",
            "--------------------------------------------------\n",
            "Policy: UCB \n",
            "Average Reward: 1.66009031545759 \n",
            "Average Regret: 0.008733708181923797\n",
            "Arm pulls: [9.944e+03 6.000e+00 2.000e+00 1.600e+01 1.000e+00 5.000e+00 4.000e+00\n",
            " 4.000e+00 4.000e+00 1.400e+01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAAFNCAYAAABv3TlzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAFNCAYAAADRi2EuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElSh/x/cIgBD6+VROYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owu13t3c0u79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}