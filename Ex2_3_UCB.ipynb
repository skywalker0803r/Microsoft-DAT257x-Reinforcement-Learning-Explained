{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Ex2.3 UCB.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywalker0803r/Microsoft-DAT257x-Reinforcement-Learning-Explained/blob/master/Ex2_3_UCB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ups5hbdT0u6B",
        "colab_type": "text"
      },
      "source": [
        "# DAT257x: Reinforcement Learning Explained\n",
        "\n",
        "## Lab 2: Bandits\n",
        "\n",
        "### Exercise 2.3: UCB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X53hKzxM2vCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "### Interface\n",
        "class Environment(object):\n",
        "\n",
        "    def reset(self):\n",
        "        raise NotImplementedError('Inheriting classes must override reset.')\n",
        "\n",
        "    def actions(self):\n",
        "        raise NotImplementedError('Inheriting classes must override actions.')\n",
        "\n",
        "    def step(self):\n",
        "        raise NotImplementedError('Inheriting classes must override step')\n",
        "\n",
        "class ActionSpace(object):\n",
        "    \n",
        "    def __init__(self, actions):\n",
        "        self.actions = actions\n",
        "        self.n = len(actions)\n",
        "        \n",
        "### BanditEnv Environment\n",
        "        \n",
        "class BanditEnv(Environment):\n",
        "    def __init__(self, num_actions = 10, distribution = \"bernoulli\", evaluation_seed=\"387\"):\n",
        "        super(BanditEnv, self).__init__()\n",
        "        \n",
        "        self.action_space = ActionSpace(range(num_actions))\n",
        "        self.distribution = distribution\n",
        "        \n",
        "        np.random.seed(evaluation_seed)\n",
        "        \n",
        "        self.reward_parameters = None\n",
        "        if distribution == \"bernoulli\":\n",
        "            self.reward_parameters = np.random.rand(num_actions)\n",
        "        elif distribution == \"normal\":\n",
        "            self.reward_parameters = (np.random.randn(num_actions), np.random.rand(num_actions))\n",
        "        elif distribution == \"heavy-tail\":\n",
        "            self.reward_parameters = np.random.rand(num_actions)\n",
        "        else:\n",
        "            print(\"Please use a supported reward distribution\", flush = True)\n",
        "            sys.exit(0)\n",
        "        \n",
        "        if distribution != \"normal\":\n",
        "            self.optimal_arm = np.argmax(self.reward_parameters)\n",
        "        else:\n",
        "            self.optimal_arm = np.argmax(self.reward_parameters[0])\n",
        "    \n",
        "    def reset(self):\n",
        "        self.is_reset = True\n",
        "        return None\n",
        "    \n",
        "    def compute_gap(self, action):\n",
        "        if self.distribution != \"normal\":\n",
        "            gap = np.absolute(self.reward_parameters[self.optimal_arm] - self.reward_parameters[action])\n",
        "        else:\n",
        "            gap = np.absolute(self.reward_parameters[0][self.optimal_arm] - self.reward_parameters[0][action])\n",
        "        return gap\n",
        "    \n",
        "    def step(self, action):\n",
        "        self.is_reset = False\n",
        "        valid_action = True\n",
        "        if (action is None or action < 0 or action >= self.action_space.n):\n",
        "            print(\"Algorithm chose an invalid action; reset reward to -inf\", flush = True)\n",
        "            reward = float(\"-inf\")\n",
        "            gap = float(\"inf\")\n",
        "            valid_action = False\n",
        "        \n",
        "        if self.distribution == \"bernoulli\":\n",
        "            if valid_action:\n",
        "                reward = np.random.binomial(1, self.reward_parameters[action])\n",
        "                gap = self.reward_parameters[self.optimal_arm] - self.reward_parameters[action]\n",
        "        elif self.distribution == \"normal\":\n",
        "            if valid_action:\n",
        "                reward = self.reward_parameters[0][action] + self.reward_parameters[1][action] * np.random.randn()\n",
        "                gap = self.reward_parameters[0][self.optimal_arm] - self.reward_parameters[0][action]\n",
        "        elif self.distribution == \"heavy-tail\":\n",
        "            if valid_action:\n",
        "                reward = self.reward_parameters[action] + np.random.standard_cauchy()\n",
        "                gap = self.reward_parameters[self.optimal_arm] - self.reward_parameters[action]        #HACK to compute expected gap\n",
        "        else:\n",
        "            print(\"Please use a supported reward distribution\", flush = True)\n",
        "            sys.exit(0)\n",
        "            \n",
        "        return(None, reward, self.is_reset, '')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import namedtuple\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "EpisodeStats = namedtuple(\"Stats\",[\"episode_lengths\", \"episode_rewards\", \"episode_running_variance\"])\n",
        "TimestepStats = namedtuple(\"Stats\",[\"cumulative_rewards\", \"regrets\"])\n",
        "\n",
        "def plot_episode_stats(stats, smoothing_window=10, hideplot=False):\n",
        "    # Plot the episode length over time\n",
        "    fig1 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(stats.episode_lengths)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Episode Length\")\n",
        "    plt.title(\"Episode Length over Time\")\n",
        "    if hideplot:\n",
        "        plt.close(fig1)\n",
        "    else:\n",
        "        plt.show(fig1)\n",
        "\n",
        "    # Plot the episode reward over time\n",
        "    fig2 = plt.figure(figsize=(10,5))\n",
        "    rewards_smoothed = pd.Series(stats.episode_rewards).rolling(smoothing_window, min_periods=smoothing_window).mean()\n",
        "    plt.plot(rewards_smoothed)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Episode Reward (Smoothed)\")\n",
        "    plt.title(\"Episode Reward over Time (Smoothed over window size {})\".format(smoothing_window))\n",
        "    if hideplot:\n",
        "        plt.close(fig2)\n",
        "    else:\n",
        "        plt.show(fig2)\n",
        "\n",
        "    return fig1, fig2\n",
        "\n",
        "def plot_pgresults(stats, smoothing_window=20, hideplot=False):\n",
        "    # Plot the episode length over time\n",
        "    fig1 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(stats.episode_lengths)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Episode Length\")\n",
        "    plt.title(\"Episode Length over Time\")\n",
        "    if hideplot:\n",
        "        plt.close(fig1)\n",
        "    else:\n",
        "        plt.show(fig1)\n",
        "\n",
        "    # Plot the episode reward over time\n",
        "    fig2 = plt.figure(figsize=(10,5))\n",
        "    rewards_smoothed = pd.Series(stats.episode_rewards).rolling(smoothing_window, min_periods=smoothing_window).mean()\n",
        "    plt.plot(rewards_smoothed)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Episode Reward (Smoothed)\")\n",
        "    plt.title(\"Episode Reward over Time (Smoothed over window size {})\".format(smoothing_window))\n",
        "    if hideplot:\n",
        "        plt.close(fig2)\n",
        "    else:\n",
        "        plt.show(fig2)\n",
        "       \n",
        "    # Plot time steps and episode number\n",
        "    fig3 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(stats.episode_running_variance)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Running Variance\")\n",
        "    plt.title(\"Running Variance over Time\")\n",
        "    if hideplot:\n",
        "        plt.close(fig3)\n",
        "    else:\n",
        "        plt.show(fig3)\n",
        "        \n",
        "    # Plot time steps and episode number\n",
        "    fig4 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(np.arange(len(stats.episode_lengths)), np.cumsum(stats.episode_lengths))\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Cumulative Episode Length\")\n",
        "    plt.title(\"Cumulative Episode Length over Time\")\n",
        "    if hideplot:\n",
        "        plt.close(fig4)\n",
        "    else:\n",
        "        plt.show(fig4)\n",
        "\n",
        "    return fig1, fig2, fig3, fig4\n",
        "\n",
        "def plot_dqnresults(stats, smoothing_window=20, hideplot=False):\n",
        "    # Plot the episode length over time\n",
        "    fig1 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(stats.episode_lengths)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Episode Length\")\n",
        "    plt.title(\"Episode Length over Time\")\n",
        "    if hideplot:\n",
        "        plt.close(fig1)\n",
        "    else:\n",
        "        plt.show(fig1)\n",
        "\n",
        "    # Plot the episode reward over time\n",
        "    fig2 = plt.figure(figsize=(10,5))\n",
        "    rewards_smoothed = pd.Series(stats.episode_rewards).rolling(smoothing_window, min_periods=smoothing_window).mean()\n",
        "    plt.plot(rewards_smoothed)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Episode Reward (Smoothed)\")\n",
        "    plt.title(\"Episode Reward over Time (Smoothed over window size {})\".format(smoothing_window))\n",
        "    if hideplot:\n",
        "        plt.close(fig2)\n",
        "    else:\n",
        "        plt.show(fig2)\n",
        "              \n",
        "    # Plot time steps and episode number\n",
        "    fig4 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(np.arange(len(stats.episode_lengths)), np.cumsum(stats.episode_lengths))\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Cumulative Episode Length\")\n",
        "    plt.title(\"Cumulative Episode Length over Time\")\n",
        "    if hideplot:\n",
        "        plt.close(fig4)\n",
        "    else:\n",
        "        plt.show(fig4)\n",
        "\n",
        "    return fig1, fig2, fig3, fig4\n",
        "\n",
        "def plot_reward_regret(stats, smoothing_window=1, hideplot=False):\n",
        "    # Plot the cumulative reward over time\n",
        "    fig1 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(stats.cumulative_rewards)\n",
        "    plt.xlabel(\"Timestep\")\n",
        "    plt.ylabel(\"Cumulative Reward\")\n",
        "    plt.title(\"Cumulative Reward over Timestep\")\n",
        "    if hideplot:\n",
        "        plt.close(fig1)\n",
        "    else:\n",
        "        plt.show(fig1)\n",
        "\n",
        "    # Plot the regret over time\n",
        "    fig2 = plt.figure(figsize=(10,5))\n",
        "    plt.plot(stats.regrets)\n",
        "    plt.xlabel(\"Timestep\")\n",
        "    plt.ylabel(\"Regret\")\n",
        "    plt.title(\"Regret over Timestep\")\n",
        "    if hideplot:\n",
        "        plt.close(fig2)\n",
        "    else:\n",
        "        plt.show(fig2)\n",
        "             \n",
        "    return fig1, fig2   \n",
        "\n",
        "def plot_arm_rewards(y, hideplot=False):\n",
        "    \n",
        "    N = len(y)\n",
        "    x = range(N)\n",
        "    width = 1/1.5\n",
        "    \n",
        "    fig1 = plt.figure(figsize=(10,5))\n",
        "    plt.bar(x, y, width)\n",
        "    \n",
        "    plt.xlabel(\"Arm\")\n",
        "    plt.ylabel(\"Probability\")\n",
        "    plt.title(\"Arm's Reward Distribution\")\n",
        "    \n",
        "    if hideplot:\n",
        "        plt.close(fig1)\n",
        "    else:\n",
        "        plt.show(fig1)\n",
        "             \n",
        "    return fig1\n",
        "import numpy as np\n",
        "import sys\n",
        "#import lib.plotting as plotting\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import pylab\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "class Experiment(object):\n",
        "    def __init__(self, env, agent):\n",
        "        \n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        \n",
        "        self.episode_length = np.array([0])\n",
        "        self.episode_reward = np.array([0])\n",
        "        \n",
        "        self.fig = pylab.figure(figsize=(10, 5))\n",
        "        gs = gridspec.GridSpec(2, 2)\n",
        "        self.ax = pylab.subplot(gs[:, 0])\n",
        "        self.ax.xaxis.set_visible(False)\n",
        "        self.ax.yaxis.set_visible(False)\n",
        "        \n",
        "        if hasattr(self.env, '_cliff'): # Hardcode to nicely display grid for cliffwalkingenv\n",
        "            self.ax.xaxis.set_visible(True)\n",
        "            self.ax.yaxis.set_visible(True)\n",
        "            self.ax.set_xticks(np.arange(-.5, 12, 1), minor=True);\n",
        "            self.ax.set_yticks(np.arange(-.5, 4, 1), minor=True);\n",
        "            self.ax.grid(which='minor', color='w', linestyle='-', linewidth=1)\n",
        "            \n",
        "        if hasattr(self.env, 'winds'): # Hardcode to nicely display grid for windygridworldenv\n",
        "            self.ax.xaxis.set_visible(True)\n",
        "            self.ax.yaxis.set_visible(True)\n",
        "            self.ax.set_xticks(np.arange(-.5, 10, 1), minor=True);\n",
        "            self.ax.set_yticks(np.arange(-.5, 7, 1), minor=True);\n",
        "            self.ax.grid(which='minor', color='w', linestyle='-', linewidth=1)\n",
        "        \n",
        "        self.ax1 = pylab.subplot(gs[0, 1])\n",
        "        self.ax1.yaxis.set_label_position(\"right\")\n",
        "        self.ax1.set_ylabel('Length')\n",
        "        \n",
        "        self.ax1.set_xlim(0, max(10, len(self.episode_length)+1))\n",
        "        self.ax1.set_ylim(0, 51)\n",
        "        \n",
        "        self.ax2 = pylab.subplot(gs[1, 1])\n",
        "        self.ax2.set_xlabel('Episode')\n",
        "        self.ax2.yaxis.set_label_position(\"right\")\n",
        "        self.ax2.set_ylabel('Reward')\n",
        "        self.ax2.set_xlim(0, max(10, len(self.episode_reward)+1))\n",
        "        self.ax2.set_ylim(0, 2)\n",
        "        \n",
        "        self.line, = self.ax1.plot(range(len(self.episode_length)),self.episode_length)\n",
        "        self.line2, = self.ax2.plot(range(len(self.episode_reward)),self.episode_reward)\n",
        "        \n",
        "    def update_display_step(self):\n",
        "        if not hasattr(self, 'imgplot'):\n",
        "            self.imgplot = self.ax.imshow(self.env.render(mode='rgb_array'), interpolation='none', cmap='viridis')\n",
        "        else:\n",
        "            self.imgplot.set_data(self.env.render(mode='rgb_array'))\n",
        "    \n",
        "        self.fig.canvas.draw()\n",
        "        \n",
        "    def update_display_episode(self):  \n",
        "        self.line.set_data(range(len(self.episode_length)),self.episode_length)\n",
        "        self.ax1.set_xlim(0, max(10, len(self.episode_length)+1))\n",
        "        self.ax1.set_ylim(0, max(self.episode_length)+1)\n",
        "        \n",
        "        self.line2.set_data(range(len(self.episode_reward)),self.episode_reward)\n",
        "        self.ax2.set_xlim(0, max(10, len(self.episode_reward)+1))\n",
        "        self.ax2.set_ylim(min(self.episode_reward)-1, max(self.episode_reward)+1)\n",
        "        \n",
        "        self.fig.canvas.draw()     \n",
        "        \n",
        "    def run_bandit(self, max_number_of_trials=1000, display_frequency=1):\n",
        "        self.fig.clf()\n",
        "        \n",
        "        print(\"Distribution:\", self.env.distribution, self.env.reward_parameters, flush = True)\n",
        "        print(\"Optimal arm:\", self.env.optimal_arm, flush = True)\n",
        "        \n",
        "        if self.env.distribution != \"normal\":\n",
        "            plot_arm_rewards(self.env.reward_parameters)\n",
        "        #else:\n",
        "            #plotting.plot_arm_rewards(self.env.reward_parameters[0])\n",
        "        \n",
        "        stats = TimestepStats(\n",
        "            cumulative_rewards=np.zeros(max_number_of_trials),\n",
        "            regrets=np.zeros(max_number_of_trials))   \n",
        "            \n",
        "        cumulative_reward = 0.0\n",
        "        cumulative_regret = 0.0\n",
        "        \n",
        "        for trial in range(max_number_of_trials):\n",
        "            action = self.agent.act()\n",
        "            \n",
        "            _ , reward, done, _ = self.env.step(action)       \n",
        "            self.agent.feedback(action, reward)\n",
        "            cumulative_reward += reward\n",
        "\n",
        "            gap = self.env.compute_gap(action)\n",
        "            if action != self.env.optimal_arm:\n",
        "                cumulative_regret += gap\n",
        "\n",
        "            stats.cumulative_rewards[trial] = cumulative_reward\n",
        "            stats.regrets[trial] = cumulative_regret\n",
        "            \n",
        "\n",
        "        print(\"--------------------------------------------------\", flush = True)\n",
        "        print(\"Policy:\", self.agent.name, \"\\nAverage Reward:\", cumulative_reward / max_number_of_trials, \\\n",
        "                \"\\nAverage Regret:\", cumulative_regret / max_number_of_trials, flush = True)\n",
        "        print(\"Arm pulls:\", self.agent.total_counts, flush = True)\n",
        "         \n",
        "        plot_reward_regret(stats)\n",
        "        \n",
        "    def run_agent(self, max_number_of_episodes=100, interactive = False, display_frequency=1):\n",
        "\n",
        "        # repeat for each episode\n",
        "        for episode_number in range(max_number_of_episodes):\n",
        "            \n",
        "            # initialize state\n",
        "            state = self.env.reset()\n",
        "            \n",
        "            done = False # used to indicate terminal state\n",
        "            R = 0 # used to display accumulated rewards for an episode\n",
        "            t = 0 # used to display accumulated steps for an episode i.e episode length\n",
        "            \n",
        "            # repeat for each step of episode, until state is terminal\n",
        "            while not done:\n",
        "                \n",
        "                # increase step counter - for display\n",
        "                t += 1\n",
        "                \n",
        "                # choose action from state \n",
        "                action = self.agent.act(state)\n",
        "                \n",
        "                # take action, observe reward and next state\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "                \n",
        "                # state <- next state\n",
        "                state = next_state\n",
        "                \n",
        "                R += reward # accumulate reward - for display\n",
        "                \n",
        "                # if interactive display, show update for each step\n",
        "                if interactive:\n",
        "                    self.update_display_step()\n",
        "            \n",
        "            self.episode_length = np.append(self.episode_length,t) # keep episode length - for display\n",
        "            self.episode_reward = np.append(self.episode_reward,R) # keep episode reward - for display \n",
        "            \n",
        "            # if interactive display, show update for the episode\n",
        "            if interactive:\n",
        "                self.update_display_episode()\n",
        "        \n",
        "        # if not interactive display, show graph at the end\n",
        "        if not interactive:\n",
        "            self.fig.clf()\n",
        "            stats = EpisodeStats(\n",
        "                episode_lengths=self.episode_length,\n",
        "                episode_rewards=self.episode_reward,\n",
        "                episode_running_variance=np.zeros(max_number_of_episodes))\n",
        "            plot_episode_stats(stats, display_frequency)\n",
        "        \n",
        "  \n",
        "    def run_qlearning(self, max_number_of_episodes=100, interactive = False, display_frequency=1):\n",
        "\n",
        "        # repeat for each episode\n",
        "        for episode_number in range(max_number_of_episodes):\n",
        "            \n",
        "            # initialize state\n",
        "            state = self.env.reset()\n",
        "            \n",
        "            done = False # used to indicate terminal state\n",
        "            R = 0 # used to display accumulated rewards for an episode\n",
        "            t = 0 # used to display accumulated steps for an episode i.e episode length\n",
        "            \n",
        "            # repeat for each step of episode, until state is terminal\n",
        "            while not done:\n",
        "                \n",
        "                t += 1 # increase step counter - for display\n",
        "                \n",
        "                # choose action from state using policy derived from Q\n",
        "                action = self.agent.act(state)\n",
        "                \n",
        "                # take action, observe reward and next state\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "                \n",
        "                # agent learn (Q-Learning update)\n",
        "                self.agent.learn(state, action, reward, next_state, done)\n",
        "                \n",
        "                # state <- next state\n",
        "                state = next_state\n",
        "                \n",
        "                R += reward # accumulate reward - for display\n",
        "                \n",
        "                # if interactive display, show update for each step\n",
        "                if interactive:\n",
        "                    self.update_display_step()\n",
        "            \n",
        "            self.episode_length = np.append(self.episode_length,t) # keep episode length - for display\n",
        "            self.episode_reward = np.append(self.episode_reward,R) # keep episode reward - for display \n",
        "            \n",
        "            # if interactive display, show update for the episode\n",
        "            if interactive:\n",
        "                self.update_display_episode()\n",
        "        \n",
        "        # if not interactive display, show graph at the end\n",
        "        if not interactive:\n",
        "            self.fig.clf()\n",
        "            stats = EpisodeStats(\n",
        "                episode_lengths=self.episode_length,\n",
        "                episode_rewards=self.episode_reward,\n",
        "                episode_running_variance=np.zeros(max_number_of_episodes))\n",
        "            plot_episode_stats(stats, display_frequency)\n",
        "            \n",
        "    def run_sarsa(self, max_number_of_episodes=100, interactive = False, display_frequency=1):\n",
        "\n",
        "        # repeat for each episode\n",
        "        for episode_number in range(max_number_of_episodes):\n",
        "            \n",
        "            # initialize state\n",
        "            state = self.env.reset()\n",
        "\n",
        "            done = False # used to indicate terminal state\n",
        "            R = 0 # used to display accumulated rewards for an episode\n",
        "            t = 0 # used to display accumulated steps for an episode i.e episode length\n",
        "            \n",
        "            # choose action from state using policy derived from Q\n",
        "            action = self.agent.act(state)\n",
        "            \n",
        "            # repeat for each step of episode, until state is terminal\n",
        "            while not done:\n",
        "                \n",
        "                t += 1 # increase step counter - for display\n",
        "                \n",
        "                # take action, observe reward and next state\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "                \n",
        "                # choose next action from next state using policy derived from Q\n",
        "                next_action = self.agent.act(next_state)\n",
        "                \n",
        "                # agent learn (SARSA update)\n",
        "                self.agent.learn(state, action, reward, next_state, next_action)\n",
        "                \n",
        "                # state <- next state, action <- next_action\n",
        "                state = next_state\n",
        "                action = next_action\n",
        "\n",
        "                R += reward # accumulate reward - for display\n",
        "                \n",
        "                # if interactive display, show update for each step\n",
        "                if interactive:\n",
        "                    self.update_display_step()\n",
        "            \n",
        "            self.episode_length = np.append(self.episode_length,t) # keep episode length - for display\n",
        "            self.episode_reward = np.append(self.episode_reward,R) # keep episode reward - for display \n",
        "            \n",
        "            # if interactive display, show update for the episode\n",
        "            if interactive:\n",
        "                self.update_display_episode()\n",
        "        \n",
        "        # if not interactive display, show graph at the end\n",
        "        if not interactive:\n",
        "            self.fig.clf()\n",
        "            stats = EpisodeStats(\n",
        "                episode_lengths=self.episode_length,\n",
        "                episode_rewards=self.episode_reward,\n",
        "                episode_running_variance=np.zeros(max_number_of_episodes))\n",
        "            plot_episode_stats(stats, display_frequency)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlGVGJIj0u6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "if \"../\" not in sys.path:\n",
        "    sys.path.append(\"../\") \n",
        "\n",
        "#from lib.envs.bandit import BanditEnv\n",
        "#from lib.simulation import Experiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4If01IDs0u6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Policy interface\n",
        "class Policy:\n",
        "    #num_actions: (int) Number of arms [indexed by 0 ... num_actions-1]\n",
        "    def __init__(self, num_actions):\n",
        "        self.num_actions = num_actions\n",
        "    \n",
        "    def act(self):\n",
        "        pass\n",
        "        \n",
        "    def feedback(self, action, reward):\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqUFN7r10u6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Greedy policy\n",
        "class Greedy(Policy):\n",
        "    def __init__(self, num_actions):\n",
        "        Policy.__init__(self, num_actions)\n",
        "        self.name = \"Greedy\"\n",
        "        self.total_rewards = np.zeros(num_actions, dtype = np.longdouble)\n",
        "        self.total_counts = np.zeros(num_actions, dtype = np.longdouble)\n",
        "    \n",
        "    def act(self):\n",
        "        current_averages = np.divide(self.total_rewards, self.total_counts, where = self.total_counts > 0)\n",
        "        current_averages[self.total_counts <= 0] = 0.5      #Correctly handles Bernoulli rewards; over-estimates otherwise\n",
        "        current_action = np.argmax(current_averages)\n",
        "        return current_action\n",
        "        \n",
        "    def feedback(self, action, reward):\n",
        "        self.total_rewards[action] += reward\n",
        "        self.total_counts[action] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB-H6bXY0u7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Epsilon Greedy policy\n",
        "class EpsilonGreedy(Greedy):\n",
        "    def __init__(self, num_actions, epsilon):\n",
        "        Greedy.__init__(self, num_actions)\n",
        "        if (epsilon is None or epsilon < 0 or epsilon > 1):\n",
        "            print(\"EpsilonGreedy: Invalid value of epsilon\", flush = True)\n",
        "            sys.exit(0)\n",
        "            \n",
        "        self.epsilon = epsilon\n",
        "        self.name = \"Epsilon Greedy\"\n",
        "    \n",
        "    def act(self):\n",
        "        choice = None\n",
        "        if self.epsilon == 0:\n",
        "            choice = 0\n",
        "        elif self.epsilon == 1:\n",
        "            choice = 1\n",
        "        else:\n",
        "            choice = np.random.binomial(1, self.epsilon)\n",
        "            \n",
        "        if choice == 1:\n",
        "            return np.random.choice(self.num_actions)\n",
        "        else:\n",
        "            current_averages = np.divide(self.total_rewards, self.total_counts, where = self.total_counts > 0)\n",
        "            current_averages[self.total_counts <= 0] = 0.5  #Correctly handles Bernoulli rewards; over-estimates otherwise\n",
        "            current_action = np.argmax(current_averages)\n",
        "            return current_action\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOkRjVaO0u7N",
        "colab_type": "text"
      },
      "source": [
        "Now let's implement a UCB algorithm. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92yoRjz_2F3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#UCB policy\n",
        "class UCB(Greedy):\n",
        "    def __init__(self, num_actions, k):\n",
        "        Greedy.__init__(self, num_actions)\n",
        "        self.name = \"UCB\"\n",
        "        self.round = 0\n",
        "        self.k = k\n",
        "        self.previous_action = num_actions - 1\n",
        "        self.num_actions = num_actions\n",
        "        self.qvalues = np.zeros(num_actions)\n",
        "        self.counts = np.zeros(num_actions)\n",
        "        self.t = 0\n",
        "        \n",
        "    def act(self):\n",
        "        if (self.round < self.k):\n",
        "            \"\"\"The first k rounds, play each arm/action once\"\"\"\n",
        "            current_action = self.previous_action + 1\n",
        "            if current_action >= self.num_actions:\n",
        "                self.round += 1\n",
        "                current_action = 0\n",
        "            self.previous_action = current_action\n",
        "                \n",
        "        if (self.round >= self.k):\n",
        "            \"\"\"play the arms with maximum average and exploration bonus\"\"\"\n",
        "            r_hats = self.total_rewards/self.total_counts\n",
        "            scores = r_hats + np.sqrt(np.log(self.t)/self.total_counts)\n",
        "            current_action = np.argmax(scores)\n",
        "            \n",
        "        return current_action\n",
        "    \n",
        "    def feedback(self, action, reward):\n",
        "        self.total_rewards[action] += reward\n",
        "        self.total_counts[action] += 1\n",
        "        self.t += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXFjYTIN0u7b",
        "colab_type": "text"
      },
      "source": [
        "Now let's prepare the simulation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COvlVuuq0u7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluation_seed = 1239\n",
        "#num_actions = 10\n",
        "#trials = 10000\n",
        "#distribution = \"bernoulli\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Njmw-dJ3l_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_seed = 1239\n",
        "num_actions = 10\n",
        "trials = 10000\n",
        "distribution = \"normal\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-fgEbBC0u7p",
        "colab_type": "text"
      },
      "source": [
        "What do you think the regret graph would look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A3Yxdf40u7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "outputId": "decf07a2-dc57-461e-d8dc-47bf47bb0a5f"
      },
      "source": [
        "env = BanditEnv(num_actions, distribution, evaluation_seed)\n",
        "agent = UCB(num_actions,k=10)\n",
        "experiment = Experiment(env, agent)\n",
        "experiment.run_bandit(trials)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution: normal (array([ 1.67210906,  0.04144904, -2.26004314,  0.55185287, -0.99557374,\n",
            "       -0.2838564 , -0.50553487, -0.05963477, -0.54748047,  0.61487342]), array([0.16003572, 0.39623439, 0.70679209, 0.13345484, 0.97314585,\n",
            "       0.28711056, 0.11221114, 0.52693607, 0.53345874, 0.62434873]))\n",
            "Optimal arm: 0\n",
            "--------------------------------------------------\n",
            "Policy: UCB \n",
            "Average Reward: 1.6526265183175954 \n",
            "Average Regret: 0.01674936020372962\n",
            "Arm pulls: [9.918e+03 9.000e+00 9.000e+00 9.000e+00 9.000e+00 9.000e+00 9.000e+00\n",
            " 9.000e+00 9.000e+00 1.000e+01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAAFNCAYAAABv3TlzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFNCAYAAACuWnPfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de7QkZX3u8e8zew+giIAyIlcBg0Q0\nEXWCxkuCdzQmaJYxoFG8BclRj5dkGYkmmuRwlkk0XkKiohI0EZSIF45ilHg8GD0HZFCCyEUHBBnk\nMoIIIsLu7t/5o2sP7bBndjfTtWszfD9r9dpVb1VXvd21enh437feSlUhSZKk7qzougKSJEn3dAYy\nSZKkjhnIJEmSOmYgkyRJ6piBTJIkqWMGMkmSpI4ZyCSpJUnen+TPu66HpOXPQCbpTpJcnuTWJD9N\nck2SE5Pcp6O6HJJkXRfn3pwkezffz/yrktwysv7Eqjq6qv56iev1f5K8YinPKWnLGcgkbcpvV9V9\ngIOARwLHtHGSJDNtHHfaksyOrlfVD6rqPvOvpvgRI2X/2UE1Jd1NGcgkbVZVXQN8kWEwAyDJtkne\nkeQHSa5tuubuNbL9jUmuTvLDJK9oWo9+qdl2YpL3JTk9yS3AkzZ1vCTbA18Adh9pedp94zom2THJ\nR5OsT3JFkrckWdEc98YkDx/Zd1XT+veAZv3ZSc5r9vu/SX51ZN/Lk/xpkvOBWzYOZYtpPuv/aJYP\nSbKu+W6ua76f5yR5VpLvJrkhyZ+NvHdFkjcluTTJ9UlOSXK/Ztt2Sf61Kb8xyTlJdk1yLPBE4Ljm\nuzqu2f+Xk5zRnOOSJM/fqI7vb7bfnOTMJA+a5HNK2nIGMkmblWRP4JnA2pHitwMPYRjSfgnYA/iL\nZv9DgTcAT222HbLAYV8AHAvsAHxtU8erqluac/9wpOXphwsc7x+AHYH9gN8EXgy8tKpuAz4FHDGy\n7/OBM6vquiSPBE4AXgncH/gAcFqSbUf2PwL4LWCnqupt9sta3AOB7bjj+/og8AfAoxkGqT9Psm+z\n72uA5zSfZ3fgx8A/NtuObD7vXk29jwZurao3A/8JvLr5rl7dhNozgJOABwCHA/+U5MCRer0Q+Gtg\nF+A84GNb+DklTchAJmlTPpPkZuBK4DrgrQBJAhwFvL6qbqiqm4H/yfA/9DAMPP9cVd+pqp8Bb1vg\n2J+tqq9X1QC4bZHjbVbT5Xk4cExV3VxVlwPvBF7U7HLSRsd6QVNGc94PVNXZVdWvqo809XnsyP7v\nraorq+rWceqziDng2KqaAz7OMAC9p6n3d4ALgUc0+x4NvLmq1jXB8m3A85pWujmGQeyXmnqfW1U3\nbeKczwYur6p/rqpeVX0LOBX4vZF9Pl9VX23O82bg15PsNYXPK2lMEzW/S7pHeU5V/UeS32QYYHYB\nbgRWAfcGzh1mMwACzI8F2x1YM3KcKxc49mjZYsdbzC7ASuCKkbIrGLZCAXwFuHeSxwDXMmyF+3Sz\n7UHAkUleM/LebZrPsLn631XXV1W/WZ4PeNeObL8VmB+P9iDg00kGI9v7wK7AvzBsHft4kp2Af2UY\n3uYWOOeDgMckuXGkbLY5xrwNn7GqfprkBobfwTQ/u6TNMJBJ2qyqOjPJicA7GHah/YhhcHhYVV21\nwFuuBvYcWV+opaVGlhc7Xi1QNupHDFuMHsSwhQlgb+Cqpv79JKcw7Hq8Fvhc0woHw8BxbFUdu5nj\nL3b+tlwJvKyqvr6J7X8J/GWSfYDTgUuAD3Pn+l7JsIv2aZs514ZrlOHdtPcDFuoaltQSuywljePd\nwNOSPKLpZvwg8K6RgfF7JHlGs+8pwEuTPDTJvYHNzsM1xvGuBe6fZMdNvL/fnPPYJDs0A9LfwLDV\naN5JwO8zHCt10kj5B4GjkzwmQ9sn+a0kO4z3tbTq/Qw/04Ngw80IhzXLT0ryK0137U0MA+l8S9q1\nDMfSzfsc8JAkL0qysnn9WpKHjuzzrCRPSLINw7FkZ1WVrWPSEjKQSVpUVa0HPkozcB/4U4aD/M9K\nchPwH8ABzb5fAN7LsKtwLXBW857bNnOKzR3vYuBk4LLmjsI73WXJcAD8LcBlDG8SOInhYP35+p/d\nbN+d4V2b8+VrgD8EjmM4aH4t8JLFvo8l8h7gNOBLzVi+s4DHNNseCHySYRi7CDiTO7og38NwrNmP\nk7y3aQ18OsNxdD8ErgH+Bhi9ceEkhmMEb2B4g8EftPi5JC0gVV21xku6J2haYi4Atp3CXYqasqY7\nel1VvaXrukj3ZLaQSZq6JM9t5gDbmWFrzP8yjEnSphnIJLXhlQynyriU4Z2Bf9RtdSRpeWutyzLJ\nCQznv7muqh7elH2CZlwIsBNwY1Ud1NwldBHDu4RgOKD06FYqJkmStMy0Oe3FiQwHyn50vqCqfn9+\nOck7gZ+M7H9pVR2EJEnSPUxrgayqvtq0fN1JM9P384Ent3V+SZKku4uuJoZ9InBtVX1vpGzfJN9i\neBv3W6rqPxc7yC677FL77LNPS1WUJEmannPPPfdHVbVqoW1dBbIjGM4rNO9qYO+quj7Joxk+Q+9h\nCz2bLclRDJ8/x957782aNWs23kWSJGnZSXLFprYt+V2WzYNxfxf4xHxZVd1WVdc3y+cyvDPrIQu9\nv6qOr6rVVbV61aoFQ6YkSdLdShfTXjwVuLiq1s0XNI8EmWmW9wP2ZzjjtiRJ0lavtUCW5GTg/wEH\nJFmX5OXNpsP5xe5KgN8Azk9yHsPHgRxdVTe0VTdJkqTlpM27LI/YRPlLFig7FTi1rbpIkiQtZ87U\nL0mS1DEDmSRJUscMZJIkSR0zkEmSJHXMQCZJktSxrmbqlyRJU3D1T27lzEvWU11X5G5utx2345AD\nHtDZ+Q1kkiTdjb37jO/xiTVXdl2Nu71DDlhlILs7WXP5DbzlMxfQG/j/IpKk7l194608bPf78uEj\nf63rqtytbTPb7SguA9mE1lzxYy6+5mae8bBdmV3hEDxJUrcO2HUHnvkrD+SBO27XdVW0BQxkE5rr\nDQA47gWPYuWMgUySJG05E8WE5pquytkV6bgmkiRpa2Egm9Bcf8DKmZAYyCRJ0nQYyCY01xvYVSlJ\nkqbKZDGh3qAMZJIkaapMFhO6vemylCRJmhYD2YR6fbssJUnSdJksJjTXL2ZtIZMkSVNkIJvQ7baQ\nSZKkKTNZTKjXH7CNgUySJE2RyWJCdllKkqRpM5BNaM4uS0mSNGUmiwkZyCRJ0rSZLCY01y/nIZMk\nSVNlIJuQ85BJkqRpM1lM6PZ+MbvCr02SJE2PyWJCc/0B28zaZSlJkqbHQDYhuywlSdK0mSwmNGeX\npSRJmrLWkkWSE5Jcl+SCkbK3JbkqyXnN61kj245JsjbJJUme0Va9ttTtdllKkqQpa7Op50Tg0AXK\n31VVBzWv0wGSHAgcDjysec8/JZlpsW53mV2WkiRp2lpLFlX1VeCGMXc/DPh4Vd1WVd8H1gIHt1W3\nLWGXpSRJmrYuksWrk5zfdGnu3JTtAVw5ss+6pmzZmesPWGmXpSRJmqKlDmTvAx4MHARcDbxz0gMk\nOSrJmiRr1q9fP+36LWquP2ClLWSSJGmKljRZVNW1VdWvqgHwQe7olrwK2Gtk1z2bsoWOcXxVra6q\n1atWrWq3whvpD4pB4RgySZI0VUuaLJLsNrL6XGD+DszTgMOTbJtkX2B/4BtLWbdxzPUHAHZZSpKk\nqZpt68BJTgYOAXZJsg54K3BIkoOAAi4HXglQVd9JcgpwIdADXlVV/bbqdldtCGR2WUqSpClqLZBV\n1RELFH94M/sfCxzbVn2mYa5fAKycsYVMkiRNj009E+ht6LL0a5MkSdNjspjA7XZZSpKkFpgsJtCb\n77J0UL8kSZoiA9kENgzqd9oLSZI0RSaLCcx3WfroJEmSNE0miwn0vMtSkiS1wEA2gd5gGMhm7bKU\nJElTZLKYQL8JZDOxhUySJE2PgWwCvcFwDNnMCgOZJEmaHgPZBJo8xqxjyCRJ0hQZyCZgC5kkSWqD\ngWwCjiGTJEltMJBNYEMgs4VMkiRNkYFsAv0N014YyCRJ0vQYyCbQs8tSkiS1wEA2AbssJUlSGwxk\nE9jQZemzLCVJ0hSZLCawoYXMMWSSJGmKDGQTcAyZJElqg4FsAv1yDJkkSZo+A9kE+v3hTP2zBjJJ\nkjRFBrIJzHdZrjCQSZKkKTKQTeCOuywNZJIkaXoMZBOYa7osV874tUmSpOkxWUzg1rk+MyvCSqe9\nkCRJU2Qgm8DP5wbca+UMcdoLSZI0RQayCdw612e7lTNdV0OSJG1lDGQTuL03YNtZvzJJkjRdraWL\nJCckuS7JBSNlf5fk4iTnJ/l0kp2a8n2S3JrkvOb1/rbqtSV6/QGzjh+TJElT1mZzz4nAoRuVnQE8\nvKp+FfgucMzItkur6qDmdXSL9brLeoNyygtJkjR1rQWyqvoqcMNGZV+qql6zehawZ1vnb0OvX8yu\nsMtSkiRNV5fp4mXAF0bW903yrSRnJnliV5XanN7ALktJkjR9s12cNMmbgR7wsaboamDvqro+yaOB\nzyR5WFXdtMB7jwKOAth7772XqsoAzPXtspQkSdO35C1kSV4CPBt4YVUVQFXdVlXXN8vnApcCD1no\n/VV1fFWtrqrVq1atWqJaD/UHxayz9EuSpClb0nSR5FDgjcDvVNXPRspXJZlplvcD9gcuW8q6jWOu\nP7CFTJIkTV1rXZZJTgYOAXZJsg54K8O7KrcFzmhmuz+ruaPyN4C/SjIHDICjq+qGBQ/cod6g2G6l\nLWSSJGm6WgtkVXXEAsUf3sS+pwKntlWXaRlOe2EgkyRJ02W6mECvP/DB4pIkaeoMZBPo9YsZx5BJ\nkqQpM5BNYDgPmV+ZJEmaLtPFBHqDYqUtZJIkacoMZBMYdln6lUmSpOkyXUygN3BQvyRJmj4D2QR6\n/fJZlpIkaeoMZBMYztTvVyZJkqbLdDGB/sCHi0uSpOkzkE1gzoeLS5KkFpguJtDz4eKSJKkFBrIx\nDQbFoHBQvyRJmjoD2Zh6gwKwhUySJE2dgWxMvcEAwDFkkiRp6kwXY7KFTJIktcVANqZe30AmSZLa\nYSAbU69vl6UkSWqH6WJM812WPstSkiRNm4FsTPNdljM+OkmSJE2Z6WJMc81dlraQSZKkaTOQjemO\nFjIDmSRJmi4D2Zg2zENml6UkSZoy08WY5lvI7LKUJEnTZiAbkzP1S5KktpguxjQ330LmGDJJkjRl\nBrIx9QcO6pckSe0wkI1pzpn6JUlSS0wXY3JQvyRJakurgSzJCUmuS3LBSNn9kpyR5HvN352b8iR5\nb5K1Sc5P8qg26zYpp72QJEltaTtdnAgculHZm4AvV9X+wJebdYBnAvs3r6OA97Vct4n4LEtJktSW\nVgNZVX0VuGGj4sOAjzTLHwGeM1L+0Ro6C9gpyW5t1m8SztQvSZLa0kX/265VdXWzfA2wa7O8B3Dl\nyH7rmrJlYX5Q/0oH9UuSpCnrNF1UVQE1yXuSHJVkTZI169evb6lmdzbfZTlrl6UkSZqyLgLZtfNd\nkc3f65ryq4C9Rvbbsyn7BVV1fFWtrqrVq1atar2y83p9B/VLkqR2dJEuTgOObJaPBD47Uv7i5m7L\nxwI/Gena7NyGFjLHkEmSpCmbbfPgSU4GDgF2SbIOeCvwduCUJC8HrgCe3+x+OvAsYC3wM+ClbdZt\nUvOD+u2ylCRJ09ZqIKuqIzax6SkL7FvAq9qsz5aYGzioX5IktcN0MaYNLWR2WUqSpCkzkI2p58PF\nJUlSSwxkY+r1B8yuCImBTJIkTZeBbEy9QTmgX5IktWKsQJbk8eOUbc3m+gNWOgeZJElqwbgJ4x/G\nLNtq9fq2kEmSpHZsdtqLJL8OPA5YleQNI5vuC8y0WbHlpjcoZmwhkyRJLVhsHrJtgPs0++0wUn4T\n8Ly2KrUc9foDVtpCJkmSWrDZQFZVZwJnJjmxqq5Icu+q+tkS1W1ZcVC/JElqy7h9cLsnuRC4GCDJ\nI5L8U3vVWn4c1C9JktoybsJ4N/AM4HqAqvov4DfaqtRy1LeFTJIktWTsJp+qunKjov6U67KszfUd\n1C9Jktox7sPFr0zyOKCSrAReC1zUXrWWn97AQf2SJKkd4zb5HA28CtgDuAo4qFm/x+j1yweLS5Kk\nVizaQpZkBnhRVb1wCeqzbM31B8zO2GUpSZKmb9GEUVV94AVLUJdlrT+whUySJLVj3DFkX0tyHPAJ\n4Jb5wqr6Ziu1WobmBsW9bSGTJEktGDeQHdT8/auRsgKePN3qLF+9/oCVtpBJkqQWjBXIqupJbVdk\nufPh4pIkqS1jBbKNHiw+7yfAuVV13nSrtDz1Bg7qlyRJ7Rg3YaxmOPXFHs3rlcChwAeTvLGlui0r\nPQf1S5Kklow7hmxP4FFV9VOAJG8FPs/w8UnnAn/bTvWWj+E8ZLaQSZKk6Rs3YTwAuG1kfQ7Ytapu\n3ah8qzXXd6Z+SZLUjnFbyD4GnJ3ks836bwMnJdkeuLCVmi0zPR8uLkmSWjLuXZZ/neQLwOOboqOr\nak2zfI+Ywb/XH9hlKUmSWjFJwtgOuKmq3gNckWTfluq0LDmoX5IktWWsQNYM4v9T4JimaCXwr21V\najkazkNmC5kkSZq+cRPGc4HfoXlsUlX9ENihrUotR3MDB/VLkqR2jDuo//aqqiQF0Azmv0uSHMDw\nmZjz9gP+AtgJ+ENgfVP+Z1V1+l09zzQNBkUVzNhlKUmSWjBuIDslyQeAnZL8IfAy4EN35YRVdQnN\nszGTzABXAZ8GXgq8q6recVeO26a5wQCAlXZZSpKkFox7l+U7kjwNuAk4APiLqjpjCud/CnBpVV2R\nLN/Wp16/ABzUL0mSWjFuCxlNADsDIMmKJC+sqo9t4fkPB04eWX91khcDa4A/rqofb+Hxp2JDILOF\nTJIktWCzCSPJfZMck+S4JE/P0KuBy4Dnb8mJk2zD8EaBf2uK3gc8mGF35tXAOzfxvqOSrEmyZv36\n9QvtMnW9DV2WtpBJkqTpW6zJ518YdlF+G3gF8BXg94DnVNVhW3juZwLfrKprAarq2qrqV9UA+CBw\n8EJvqqrjq2p1Va1etWrVFlZhPL3BsIXMQf2SJKkNi3VZ7ldVvwKQ5EMMW672rqqfT+HcRzDSXZlk\nt6q6ull9LnDBFM4xFXP9poXMmfolSVILFgtkc/MLVdVPsm4aYayZNuNpwCtHiv82yUFAAZdvtK1T\nd4whs4VMkiRN32KB7BFJbmqWA9yrWQ9QVXXfu3LSqroFuP9GZS+6K8daCvNjyBzUL0mS2rDZQFZV\nM0tVkeVsfgyZ015IkqQ22OQzBuchkyRJbTKQjWHDoH67LCVJUgtMGGPY0GXpoH5JktQCA9kY7uiy\n9OuSJEnTZ8IYwx13WdpCJkmSps9ANgYH9UuSpDYZyMbgoH5JktQmE8YYHNQvSZLaZCAbgxPDSpKk\nNhnIxtBruiy9y1KSJLXBhDEGHy4uSZLaZCAbw9zAQf2SJKk9Jowx9B1DJkmSWmQgG8OcM/VLkqQW\nmTDGsGFQv2PIJElSCwxkY3AeMkmS1CYD2Rg2zNRvl6UkSWqBCWMM/UGRwAoH9UuSpBYYyMYw1y9b\nxyRJUmtMGWPo9QeOH5MkSa0xkI2hNyjnIJMkSa0xkI2hNxg4S78kSWqNKWMMvX4xYwuZJElqiYFs\nDHP9soVMkiS1xpQxht7AQf2SJKk9BrIx9PoO6pckSe0xkI2hNxj4YHFJktSa2a5OnORy4GagD/Sq\nanWS+wGfAPYBLgeeX1U/7qqO83r9sstSkiS1putmnydV1UFVtbpZfxPw5araH/hys965uUEx66B+\nSZLUkuWWMg4DPtIsfwR4Tod12aDXH7DSMWSSJKklXQayAr6U5NwkRzVlu1bV1c3yNcCu3VTtF/UG\n5YPFJUlSazobQwY8oaquSvIA4IwkF49urKpKUhu/qQlvRwHsvffeS1LRwaDYduVya0yUJElbi85S\nRlVd1fy9Dvg0cDBwbZLdAJq/1y3wvuOranVVrV61atWS1LU3KGa8y1KSJLWkk5SRZPskO8wvA08H\nLgBOA45sdjsS+GwX9dtYf1B4k6UkSWpLV12WuwKfTjJfh5Oq6t+TnAOckuTlwBXA8zuq3y/o20Im\nSZJa1Ekgq6rLgEcsUH498JSlr9Hm9QfO1C9Jktpjs88YeoMBMwYySZLUEgPZGIZdlgYySZLUDgPZ\nGPpll6UkSWqPgWwM/b4tZJIkqT0GsjH07LKUJEktMpCNYVAGMkmS1B4D2Rh6TnshSZJaZCAbw3AM\nmV+VJElqhyljDMMxZF3XQpIkba2MGWPoly1kkiSpPaaMMfjoJEmS1CYD2SIGg3KmfkmS1CoD2SJu\n6w0A2G7lTMc1kSRJWysD2SJunesDcK+VflWSJKkdpoxFbAhk29hCJkmS2mEgW8TPm0C27ayBTJIk\ntcNAtohevwBY6URkkiSpJaaMRfQGw0H9szPeZSlJktphIFvEfAuZ85BJkqS2GMgWcUcLmV+VJElq\nhyljERvGkNlCJkmSWmIgW0RvMAxkztQvSZLaYiBbxFzfLktJktQuU8Yi+oP5aS9sIZMkSe0wkC1i\nrm+XpSRJapeBbBHzd1k6MawkSWqLKWMR812WzkMmSZLaYiBbxNyGiWH9qiRJUjuWPGUk2SvJV5Jc\nmOQ7SV7blL8tyVVJzmtez1rqui2k1/fRSZIkqV2zHZyzB/xxVX0zyQ7AuUnOaLa9q6re0UGdNqln\nl6UkSWrZkgeyqroauLpZvjnJRcAeS12PcfWch0ySJLWs05SRZB/gkcDZTdGrk5yf5IQkO3dWsREb\nWsjsspQkSS3pLJAluQ9wKvC6qroJeB/wYOAghi1o79zE+45KsibJmvXr17deT7ssJUlS2zoJZElW\nMgxjH6uqTwFU1bVV1a+qAfBB4OCF3ltVx1fV6qpavWrVqtbruqHL0rssJUlSS7q4yzLAh4GLqurv\nR8p3G9ntucAFS123hdwx7YUtZJIkqR1d3GX5eOBFwLeTnNeU/RlwRJKDgAIuB17ZQd3upD8oVgRW\nGMgkSVJLurjL8mvAQunm9KWuyzjmBgPvsJQkSa0yaSyi1y9W2jomSZJaZCBbRH9QzBjIJElSiwxk\ni5jrD1hpl6UkSWqRSWMR/UE5KawkSWqVgWwRc/1yDjJJktQqk8YieoOBLWSSJKlVBrJF9AblpLCS\nJKlVBrJF9PoDuywlSVKrTBqL6PUd1C9JktplIFtEb1DO1C9Jklpl0lhEbzBwDJkkSWqVgWwRw2kv\nDGSSJKk9BrJF9AflTP2SJKlVJo1F9PoDn2UpSZJaZSBbhPOQSZKkthnIFuGzLCVJUtsMZIsYtpD5\nNUmSpPaYNBbRH5RjyCRJUqsMZItwHjJJktQ2A9ki+n1byCRJUrsMZIvoOahfkiS1zEC2CMeQSZKk\nthnIFuFdlpIkqW0mjUX0B8WK2EImSZLaYyBbRG8wcAyZJElqlYFsEYMBjiGTJEmtMpAtwnnIJElS\n2wxkmzEYFIOyhUySJLVr2QWyJIcmuSTJ2iRv6rIu/SoAW8gkSVKrllUgSzID/CPwTOBA4IgkB3ZV\nn/5gGMhmnPZCkiS1aLkljYOBtVV1WVXdDnwcOKyryvQGtpBJkqT2LbdAtgdw5cj6uqZsgyRHJVmT\nZM369etbrUy/P99CZiCTJEntme26ApOqquOB4wFWr15dbZ5r+21n+NxrnsCu992uzdNIkqR7uOUW\nyK4C9hpZ37Mp68TszAoevseOXZ1ekiTdQyy3LstzgP2T7JtkG+Bw4LSO6yRJktSqZdVCVlW9JK8G\nvgjMACdU1Xc6rpYkSVKrllUgA6iq04HTu66HJEnSUlluXZaSJEn3OAYySZKkjhnIJEmSOmYgkyRJ\n6piBTJIkqWMGMkmSpI4ZyCRJkjqWqlYfB9mqJOuBK5bgVLsAP1qC82h8XpPlyeuy/HhNlievy/Kz\nFNfkQVW1aqENd+tAtlSSrKmq1V3XQ3fwmixPXpflx2uyPHldlp+ur4ldlpIkSR0zkEmSJHXMQDae\n47uugO7Ea7I8eV2WH6/J8uR1WX46vSaOIZMkSeqYLWSSJEkdM5BtRpJDk1ySZG2SN3Vdn61Zkr2S\nfCXJhUm+k+S1Tfn9kpyR5HvN352b8iR5b3Ntzk/yqJFjHdns/70kR3b1mbYmSWaSfCvJ55r1fZOc\n3Xz/n0iyTVO+bbO+ttm+z8gxjmnKL0nyjG4+ydYhyU5JPpnk4iQXJfl1fyvdS/L65t+vC5KcnGQ7\nfytLK8kJSa5LcsFI2dR+G0keneTbzXvemyRTq3xV+VrgBcwAlwL7AdsA/wUc2HW9ttYXsBvwqGZ5\nB+C7wIHA3wJvasrfBPxNs/ws4AtAgMcCZzfl9wMua/7u3Czv3PXnu7u/gDcAJwGfa9ZPAQ5vlt8P\n/FGz/N+A9zfLhwOfaJYPbH5D2wL7Nr+tma4/1931BXwEeEWzvA2wk7+Vzq/JHsD3gXs166cAL/G3\nsuTX4TeARwEXjJRN7bcBfKPZN817nzmtuttCtmkHA2ur6rKquh34OHBYx3XaalXV1VX1zWb5ZuAi\nhv/AHcbwPz40f5/TLB8GfLSGzgJ2SrIb8AzgjKq6oap+DJwBHLqEH2Wrk2RP4LeADzXrAZ4MfLLZ\nZePrMn+9Pgk8pdn/MODjVXVbVX0fWMvwN6YJJdmR4X90PgxQVbdX1Y34W1kOZoF7JZkF7g1cjb+V\nJVVVXwVu2Kh4Kr+NZtt9q+qsGqazj44ca4sZyDZtD+DKkfV1TZla1jTdPxI4G9i1qq5uNl0D7Nos\nb+r6eN2m793AG4FBs35/4Maq6jXro9/xhu+/2f6TZn+vy/TsC6wH/rnpRv5Qku3xt9KpqroKeAfw\nA4ZB7CfAufhbWQ6m9dvYo1neuHwqDGRaVpLcBzgVeF1V3TS6rfk/Em8LXkJJng1cV1Xndl0XbTDL\nsEvmfVX1SOAWht0wG/hbWXrNuKTDGAbm3YHtscVx2VnOvw0D2aZdBew1sr5nU6aWJFnJMIx9rKo+\n1RRf2zQT0/y9rinf1PXxuk3X44HfSXI5w277JwPvYdi0P9vsM/odb/j+m+07AtfjdZmmdcC6qjq7\nWf8kw4Dmb6VbTwW+X1Xrq9qVuc0AAAO/SURBVGoO+BTD34+/le5N67dxVbO8cflUGMg27Rxg/+YO\nmW0YDro8reM6bbWasRMfBi6qqr8f2XQaMH+Hy5HAZ0fKX9zcJfNY4CdNk/QXgacn2bn5P9anN2W6\nC6rqmKras6r2Yfgb+N9V9ULgK8Dzmt02vi7z1+t5zf7VlB/e3Fm2L7A/w8GxmlBVXQNcmeSApugp\nwIX4W+naD4DHJrl38+/Z/HXxt9K9qfw2mm03JXlsc41fPHKsLdf1HRHL+cXwDozvMrzL5c1d12dr\nfgFPYNiMfD5wXvN6FsMxFV8Gvgf8B3C/Zv8A/9hcm28Dq0eO9TKGA2HXAi/t+rNtLS/gEO64y3I/\nhv+RWAv8G7BtU75ds7622b7fyPvf3FyvS5jinUn3xBdwELCm+b18huGdYP5Wur8ufwlcDFwA/AvD\nOyX9rSztNTiZ4Ri+OYatyS+f5m8DWN1c30uB42gm2J/Gy5n6JUmSOmaXpSRJUscMZJIkSR0zkEmS\nJHXMQCZJktQxA5kkSVLHZhffRZKWnyTzt7IDPBDoM3ykEMDPqupxLZ13H+BxVXVSG8eXdM/ktBeS\n7vaSvA34aVW9YwnOdQjwJ1X17LbPJemewy5LSVudJD9t/h6S5Mwkn01yWZK3J3lhkm8k+XaSBzf7\nrUpyapJzmtfjm/LfTHJe8/pWkh2AtwNPbMpen2Qmyd817zs/yStHzv3VJJ9PckmS9yfx31xJC7LL\nUtLW7hHAQ4EbgMuAD1XVwUleC7wGeB3D53O+q6q+lmRvho9OeSjwJ8CrqurrzYPvf87wQd4bWsiS\nHMXwkSu/lmRb4OtJvtSc+2DgQOAK4N+B32X47ElJ+gUGMklbu3Nq+Aw6klwKzIelbwNPapafChw4\nfDwdAPdtAtjXgb9P8jHgU1W1bmSfeU8HfjXJ/PMKd2T4/MHbgW9U1WXNuU9m+IgwA5mkOzGQSdra\n3TayPBhZH3DHv4ErgMdW1c83eu/bk3ye4XNVv57kGQscP8BrquoXHszdjDXbeJCug3YlLcjxDJI0\nbDV7zfxKkoOavw+uqm9X1d8A5wC/DNwM7DDy3i8Cf5RkZfOehyTZvtl2cJJ9m7Fjvw98rf2PIunu\nyEAmSfDfgdXNoPwLgaOb8tcluSDJ+cAc8AXgfKCf5L+SvB74EHAh8M0kFwAf4I6Wt3OA44CLgO8D\nn16yTyTpbsVpLySpBU6PIWkStpBJkiR1zBYySZKkjtlCJkmS1DEDmSRJUscMZJIkSR0zkEmSJHXM\nQCZJktQxA5kkSVLH/j88yGcrgd2MXAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owu13t3c0u79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}